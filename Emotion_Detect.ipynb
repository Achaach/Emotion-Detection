{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "568f8c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-15 18:16:43.906085: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow.keras.models import Sequential \n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8eb902cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 images belonging to 7 classes.\n",
      "Found 7178 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "#Initialize\n",
    "train_dir = 'data/train'\n",
    "val_dir = 'data/test'\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(48,48),\n",
    "        batch_size=64,\n",
    "        color_mode=\"grayscale\",\n",
    "        class_mode='categorical')\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "        val_dir,\n",
    "        target_size=(48,48),\n",
    "        batch_size=64,\n",
    "        color_mode=\"grayscale\",\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530e9913",
   "metadata": {},
   "source": [
    "Now we can build the convolution network architecture to train the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6e492f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-14 18:25:09.528232: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "emotion_model = Sequential()\n",
    "emotion_model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(48,48,1)))\n",
    "emotion_model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "emotion_model.add(Dropout(0.25))\n",
    "emotion_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "emotion_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "emotion_model.add(Dropout(0.25))\n",
    "emotion_model.add(Flatten())\n",
    "emotion_model.add(Dense(1024, activation='relu'))\n",
    "emotion_model.add(Dropout(0.5))\n",
    "emotion_model.add(Dense(7, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1e4c2f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hp/m_3sfw2d3gnd52gvxwg38bk00000gn/T/ipykernel_33218/1130765543.py:4: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  emotion_model_info = emotion_model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "448/448 [==============================] - 210s 466ms/step - loss: 1.7980 - accuracy: 0.2647 - val_loss: 1.6980 - val_accuracy: 0.3449\n",
      "Epoch 2/30\n",
      "448/448 [==============================] - 239s 533ms/step - loss: 1.6272 - accuracy: 0.3646 - val_loss: 1.5473 - val_accuracy: 0.4129\n",
      "Epoch 3/30\n",
      "448/448 [==============================] - 233s 520ms/step - loss: 1.5320 - accuracy: 0.4103 - val_loss: 1.4763 - val_accuracy: 0.4379\n",
      "Epoch 4/30\n",
      "448/448 [==============================] - 194s 432ms/step - loss: 1.4593 - accuracy: 0.4421 - val_loss: 1.3936 - val_accuracy: 0.4706\n",
      "Epoch 5/30\n",
      "448/448 [==============================] - 179s 398ms/step - loss: 1.3945 - accuracy: 0.4655 - val_loss: 1.3415 - val_accuracy: 0.4869\n",
      "Epoch 6/30\n",
      "448/448 [==============================] - 190s 425ms/step - loss: 1.3377 - accuracy: 0.4942 - val_loss: 1.2944 - val_accuracy: 0.5078\n",
      "Epoch 7/30\n",
      "448/448 [==============================] - 183s 408ms/step - loss: 1.2951 - accuracy: 0.5082 - val_loss: 1.2694 - val_accuracy: 0.5176\n",
      "Epoch 8/30\n",
      "448/448 [==============================] - 183s 409ms/step - loss: 1.2551 - accuracy: 0.5272 - val_loss: 1.2397 - val_accuracy: 0.5315\n",
      "Epoch 9/30\n",
      "448/448 [==============================] - 192s 428ms/step - loss: 1.2188 - accuracy: 0.5396 - val_loss: 1.2145 - val_accuracy: 0.5325\n",
      "Epoch 10/30\n",
      "448/448 [==============================] - 199s 444ms/step - loss: 1.1933 - accuracy: 0.5505 - val_loss: 1.2021 - val_accuracy: 0.5448\n",
      "Epoch 11/30\n",
      "448/448 [==============================] - 194s 433ms/step - loss: 1.1640 - accuracy: 0.5598 - val_loss: 1.1676 - val_accuracy: 0.5547\n",
      "Epoch 12/30\n",
      "448/448 [==============================] - 211s 470ms/step - loss: 1.1333 - accuracy: 0.5762 - val_loss: 1.1655 - val_accuracy: 0.5547\n",
      "Epoch 13/30\n",
      "448/448 [==============================] - 183s 409ms/step - loss: 1.1145 - accuracy: 0.5838 - val_loss: 1.1427 - val_accuracy: 0.5709\n",
      "Epoch 14/30\n",
      "448/448 [==============================] - 182s 406ms/step - loss: 1.0872 - accuracy: 0.5929 - val_loss: 1.1323 - val_accuracy: 0.5717\n",
      "Epoch 15/30\n",
      "448/448 [==============================] - 180s 401ms/step - loss: 1.0601 - accuracy: 0.6060 - val_loss: 1.1231 - val_accuracy: 0.5787\n",
      "Epoch 16/30\n",
      "448/448 [==============================] - 180s 400ms/step - loss: 1.0402 - accuracy: 0.6125 - val_loss: 1.1070 - val_accuracy: 0.5840\n",
      "Epoch 17/30\n",
      "448/448 [==============================] - 172s 384ms/step - loss: 1.0183 - accuracy: 0.6244 - val_loss: 1.1018 - val_accuracy: 0.5852\n",
      "Epoch 18/30\n",
      "448/448 [==============================] - 175s 391ms/step - loss: 0.9936 - accuracy: 0.6310 - val_loss: 1.1133 - val_accuracy: 0.5830\n",
      "Epoch 19/30\n",
      "448/448 [==============================] - 204s 454ms/step - loss: 0.9699 - accuracy: 0.6411 - val_loss: 1.0854 - val_accuracy: 0.5940\n",
      "Epoch 20/30\n",
      "448/448 [==============================] - 191s 427ms/step - loss: 0.9494 - accuracy: 0.6481 - val_loss: 1.0807 - val_accuracy: 0.6017\n",
      "Epoch 21/30\n",
      "448/448 [==============================] - 173s 386ms/step - loss: 0.9219 - accuracy: 0.6595 - val_loss: 1.0817 - val_accuracy: 0.6021\n",
      "Epoch 22/30\n",
      "448/448 [==============================] - 176s 392ms/step - loss: 0.9064 - accuracy: 0.6644 - val_loss: 1.0784 - val_accuracy: 0.5996\n",
      "Epoch 23/30\n",
      "448/448 [==============================] - 197s 440ms/step - loss: 0.8876 - accuracy: 0.6750 - val_loss: 1.0724 - val_accuracy: 0.5993\n",
      "Epoch 24/30\n",
      "448/448 [==============================] - 205s 457ms/step - loss: 0.8610 - accuracy: 0.6851 - val_loss: 1.0792 - val_accuracy: 0.6035\n",
      "Epoch 25/30\n",
      "448/448 [==============================] - 209s 467ms/step - loss: 0.8422 - accuracy: 0.6925 - val_loss: 1.0791 - val_accuracy: 0.6064\n",
      "Epoch 26/30\n",
      "448/448 [==============================] - 225s 501ms/step - loss: 0.8157 - accuracy: 0.7019 - val_loss: 1.0616 - val_accuracy: 0.6108\n",
      "Epoch 27/30\n",
      "448/448 [==============================] - 251s 560ms/step - loss: 0.7988 - accuracy: 0.7080 - val_loss: 1.0613 - val_accuracy: 0.6165\n",
      "Epoch 28/30\n",
      "448/448 [==============================] - 218s 485ms/step - loss: 0.7664 - accuracy: 0.7209 - val_loss: 1.0627 - val_accuracy: 0.6159\n",
      "Epoch 29/30\n",
      "448/448 [==============================] - 233s 520ms/step - loss: 0.7549 - accuracy: 0.7256 - val_loss: 1.0723 - val_accuracy: 0.6143\n",
      "Epoch 30/30\n",
      "448/448 [==============================] - 228s 509ms/step - loss: 0.7273 - accuracy: 0.7361 - val_loss: 1.0827 - val_accuracy: 0.6134\n"
     ]
    }
   ],
   "source": [
    "#Compile and train the model:\n",
    "\n",
    "#emotion_model.compile(loss='categorical_crossentropy',optimizer=Adam(lr=0.0001, decay=1e-6),metrics=['accuracy'])\n",
    "#emotion_model_info = emotion_model.fit_generator(\n",
    "#        train_generator,\n",
    "#        steps_per_epoch=28709 // 64,\n",
    "#        epochs=30,\n",
    "#        validation_data=validation_generator,\n",
    "#        validation_steps=7178 // 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5e36c1",
   "metadata": {},
   "source": [
    "Now save the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e344ec41",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_model.save_weights('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bb3557c",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_model.load_weights('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e83b3541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 368ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m bounding_box \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mCascadeClassifier(cv2\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mhaarcascades \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhaarcascade_frontalface_default.xml\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m gray_frame \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(frame, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[0;32m---> 12\u001b[0m num_faces \u001b[38;5;241m=\u001b[39m \u001b[43mbounding_box\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetectMultiScale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgray_frame\u001b[49m\u001b[43m,\u001b[49m\u001b[43mscaleFactor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mminNeighbors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (x, y, w, h) \u001b[38;5;129;01min\u001b[39;00m num_faces:\n\u001b[1;32m     15\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mrectangle(frame, (x, y\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m50\u001b[39m), (x\u001b[38;5;241m+\u001b[39mw, y\u001b[38;5;241m+\u001b[39mh\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m10\u001b[39m), (\u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cv2.ocl.setUseOpenCL(False)\n",
    "\n",
    "emotion_dict = {0: \"Angry\", 1: \"Disgusted\", 2: \"Fearful\", 3: \"Happy\", 4: \"Neutral\", 5: \"Sad\", 6: \"Surprised\"}\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    bounding_box = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    num_faces = bounding_box.detectMultiScale(gray_frame,scaleFactor=1.3, minNeighbors=5)\n",
    "\n",
    "    for (x, y, w, h) in num_faces:\n",
    "        cv2.rectangle(frame, (x, y-50), (x+w, y+h+10), (255, 0, 0), 2)\n",
    "        roi_gray_frame = gray_frame[y:y + h, x:x + w]\n",
    "        cropped_img = np.expand_dims(np.expand_dims(cv2.resize(roi_gray_frame, (48, 48)), -1), 0)\n",
    "        emotion_prediction = emotion_model.predict(cropped_img)\n",
    "        maxindex = int(np.argmax(emotion_prediction))\n",
    "        cv2.putText(frame, emotion_dict[maxindex], (x+20, y-60), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow('Video', cv2.resize(frame,(1200,860),interpolation = cv2.INTER_CUBIC))\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35e5893",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
